{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.24.2-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp39-cp39-win_amd64.whl (267 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fourlab\\anaconda3\\envs\\p391\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fourlab\\anaconda3\\envs\\p391\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fourlab\\anaconda3\\envs\\p391\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.0.1-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fourlab\\anaconda3\\envs\\p391\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, tqdm, requests, pyyaml, filelock, tokenizers, regex, numpy, huggingface-hub, transformers\n",
      "Successfully installed charset-normalizer-3.0.1 filelock-3.9.0 huggingface-hub-0.12.1 idna-3.4 numpy-1.24.2 pyyaml-6.0 regex-2022.10.31 requests-2.28.2 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.26.1 urllib3-1.26.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "straug 0.1.2 requires magickwand, which is not installed.\n",
      "straug 0.1.2 requires opencv-python, which is not installed.\n",
      "straug 0.1.2 requires pillow, which is not installed.\n",
      "straug 0.1.2 requires scikit-image, which is not installed.\n",
      "straug 0.1.2 requires torchvision, which is not installed.\n",
      "straug 0.1.2 requires Wand, which is not installed.\n",
      "onnxruntime 1.11.1 requires flatbuffers, which is not installed.\n",
      "onnxruntime 1.11.1 requires protobuf, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fourlab\\\\Channel-LM-Prompting'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fourlab\\anaconda3\\envs\\p391\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.9.1+cu111'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (632, 632)\n",
      "1 (373, 373)\n",
      "2 (7818, 1049)\n",
      "2\n",
      "3 (764, 764)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "prefixes =  [[632, 373, 7818, 764], [632, 373, 1049, 764]]\n",
    "\n",
    "\n",
    "\n",
    "# idx = [idx for idx, _prefixes in enumerate(zip(*prefixes)) if not np.all([_prefixes[0]==_prefix for _prefix in _prefixes])][0]\n",
    "\n",
    "# print(idx)\n",
    "\n",
    "\n",
    "for idx, _prefixes in enumerate(zip(*prefixes)):\n",
    "    print(idx , _prefixes)\n",
    "    if not np.all([_prefixes[0]==_prefix for _prefix in _prefixes]):\n",
    "        print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [6.388953685760498,\n",
       "  6.901304244995117,\n",
       "  6.969942569732666,\n",
       "  6.494942665100098,\n",
       "  6.413811683654785,\n",
       "  7.015511512756348,\n",
       "  6.516026496887207,\n",
       "  6.686415672302246,\n",
       "  6.680446624755859,\n",
       "  6.8011274337768555,\n",
       "  6.644670486450195,\n",
       "  5.911459922790527,\n",
       "  5.634354591369629]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses =  [[6.388953685760498, 6.901304244995117,  6.969942569732666, 6.494942665100098, 6.413811683654785, 7.015511512756348, 6.516026496887207, 6.686415672302246, 6.680446624755859, 6.8011274337768555, 6.644670486450195, 5.911459922790527, 5.634354591369629]]\n",
    "\n",
    "gg ={str(i): loss for i, loss in enumerate(losses)}\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/20/2023 11:14:39 - INFO - __main__ - Namespace(do_train=False, do_zeroshot=True, do_check=False, use_calibration=False, use_demonstrations=False, ensemble=False, prompt_tune=False, head_tune=False, transform_tune=False, log_file=None, task='SST-2', train_task=None, k='16', seed='100', train_seed=1, lr=1e-05, warmup_steps=0, batch_size=32, data_dir='data', out_dir='out', split='test', method='direct', n_prefix=20, gpt2='gpt2-large')\n",
      "02/20/2023 11:14:40 - INFO - __main__ - direct SST-2\n",
      "02/20/2023 11:14:41 - INFO - __main__ - Checking the first example...\n",
      "02/20/2023 11:14:41 - INFO - __main__ - Input:\n",
      "02/20/2023 11:14:41 - INFO - __main__ - <|endoftext|>one long string of cliches. A\n",
      "02/20/2023 11:14:41 - INFO - __main__ - Output:\n",
      "02/20/2023 11:14:41 - INFO - __main__ -  terrible one.<|endoftext|>\n",
      "02/20/2023 11:14:41 - INFO - __main__ - out\\gpt2-large\\direct\\SST-2\\test-t=0.pkl\n",
      "02/20/2023 11:14:41 - INFO - __main__ - Loading the model\n",
      "02/20/2023 11:14:50 - INFO - __main__ - Finished loading the model\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:26,  1.03it/s]\n",
      "  7%|▋         | 2/28 [00:01<00:15,  1.71it/s]\n",
      " 11%|█         | 3/28 [00:01<00:11,  2.17it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:09,  2.48it/s]\n",
      " 18%|█▊        | 5/28 [00:02<00:08,  2.70it/s]\n",
      " 21%|██▏       | 6/28 [00:02<00:07,  2.84it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:07,  2.94it/s]\n",
      " 29%|██▊       | 8/28 [00:03<00:06,  3.01it/s]\n",
      " 32%|███▏      | 9/28 [00:03<00:06,  3.07it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.10it/s]\n",
      " 39%|███▉      | 11/28 [00:04<00:05,  3.12it/s]\n",
      " 43%|████▎     | 12/28 [00:04<00:05,  3.13it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.15it/s]\n",
      " 50%|█████     | 14/28 [00:05<00:04,  3.15it/s]\n",
      " 54%|█████▎    | 15/28 [00:05<00:04,  3.15it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.15it/s]\n",
      " 61%|██████    | 17/28 [00:06<00:03,  3.16it/s]\n",
      " 64%|██████▍   | 18/28 [00:06<00:03,  3.17it/s]\n",
      " 68%|██████▊   | 19/28 [00:06<00:02,  3.17it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.17it/s]\n",
      " 75%|███████▌  | 21/28 [00:07<00:02,  3.17it/s]\n",
      " 79%|███████▊  | 22/28 [00:07<00:01,  3.18it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.17it/s]\n",
      " 86%|████████▌ | 24/28 [00:08<00:01,  3.17it/s]\n",
      " 89%|████████▉ | 25/28 [00:08<00:00,  3.17it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.18it/s]\n",
      " 96%|█████████▋| 27/28 [00:09<00:00,  3.19it/s]\n",
      "100%|██████████| 28/28 [00:09<00:00,  3.03it/s]\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:08,  3.15it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:08,  3.16it/s]\n",
      " 11%|█         | 3/28 [00:00<00:07,  3.17it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:07,  3.16it/s]\n",
      " 18%|█▊        | 5/28 [00:01<00:07,  3.17it/s]\n",
      " 21%|██▏       | 6/28 [00:01<00:06,  3.17it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:06,  3.17it/s]\n",
      " 29%|██▊       | 8/28 [00:02<00:06,  3.17it/s]\n",
      " 32%|███▏      | 9/28 [00:02<00:05,  3.18it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.18it/s]\n",
      " 39%|███▉      | 11/28 [00:03<00:05,  3.18it/s]\n",
      " 43%|████▎     | 12/28 [00:03<00:05,  3.18it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.19it/s]\n",
      " 50%|█████     | 14/28 [00:04<00:04,  3.18it/s]\n",
      " 54%|█████▎    | 15/28 [00:04<00:04,  3.18it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.18it/s]\n",
      " 61%|██████    | 17/28 [00:05<00:03,  3.17it/s]\n",
      " 64%|██████▍   | 18/28 [00:05<00:03,  3.17it/s]\n",
      " 68%|██████▊   | 19/28 [00:05<00:02,  3.16it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.15it/s]\n",
      " 75%|███████▌  | 21/28 [00:06<00:02,  3.14it/s]\n",
      " 79%|███████▊  | 22/28 [00:06<00:01,  3.14it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.13it/s]\n",
      " 86%|████████▌ | 24/28 [00:07<00:01,  3.14it/s]\n",
      " 89%|████████▉ | 25/28 [00:07<00:00,  3.15it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.15it/s]\n",
      " 96%|█████████▋| 27/28 [00:08<00:00,  3.16it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.25it/s]\n",
      "02/20/2023 11:15:08 - INFO - __main__ - 0.5412844036697247\n",
      "02/20/2023 11:15:09 - INFO - __main__ - Checking the first example...\n",
      "02/20/2023 11:15:09 - INFO - __main__ - Input:\n",
      "02/20/2023 11:15:09 - INFO - __main__ - <|endoftext|>one long string of cliches. It was\n",
      "02/20/2023 11:15:09 - INFO - __main__ - Output:\n",
      "02/20/2023 11:15:09 - INFO - __main__ -  terrible.<|endoftext|>\n",
      "02/20/2023 11:15:09 - INFO - __main__ - out\\gpt2-large\\direct\\SST-2\\test-t=1.pkl\n",
      "02/20/2023 11:15:09 - INFO - __main__ - Loading the model\n",
      "02/20/2023 11:15:18 - INFO - __main__ - Finished loading the model\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:09,  2.74it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:08,  2.99it/s]\n",
      " 11%|█         | 3/28 [00:00<00:08,  3.07it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:07,  3.12it/s]\n",
      " 18%|█▊        | 5/28 [00:01<00:07,  3.15it/s]\n",
      " 21%|██▏       | 6/28 [00:01<00:06,  3.16it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:06,  3.17it/s]\n",
      " 29%|██▊       | 8/28 [00:02<00:06,  3.18it/s]\n",
      " 32%|███▏      | 9/28 [00:02<00:05,  3.18it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.18it/s]\n",
      " 39%|███▉      | 11/28 [00:03<00:05,  3.18it/s]\n",
      " 43%|████▎     | 12/28 [00:03<00:05,  3.18it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.19it/s]\n",
      " 50%|█████     | 14/28 [00:04<00:04,  3.19it/s]\n",
      " 54%|█████▎    | 15/28 [00:04<00:04,  3.18it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.18it/s]\n",
      " 61%|██████    | 17/28 [00:05<00:03,  3.19it/s]\n",
      " 64%|██████▍   | 18/28 [00:05<00:03,  3.19it/s]\n",
      " 68%|██████▊   | 19/28 [00:06<00:02,  3.19it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.19it/s]\n",
      " 75%|███████▌  | 21/28 [00:06<00:02,  3.19it/s]\n",
      " 79%|███████▊  | 22/28 [00:06<00:01,  3.18it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.19it/s]\n",
      " 86%|████████▌ | 24/28 [00:07<00:01,  3.19it/s]\n",
      " 89%|████████▉ | 25/28 [00:07<00:00,  3.19it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.19it/s]\n",
      " 96%|█████████▋| 27/28 [00:08<00:00,  3.20it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.25it/s]\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:08,  3.19it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:08,  3.20it/s]\n",
      " 11%|█         | 3/28 [00:00<00:07,  3.20it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:07,  3.20it/s]\n",
      " 18%|█▊        | 5/28 [00:01<00:07,  3.20it/s]\n",
      " 21%|██▏       | 6/28 [00:01<00:06,  3.20it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:06,  3.20it/s]\n",
      " 29%|██▊       | 8/28 [00:02<00:06,  3.20it/s]\n",
      " 32%|███▏      | 9/28 [00:02<00:05,  3.20it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.20it/s]\n",
      " 39%|███▉      | 11/28 [00:03<00:05,  3.20it/s]\n",
      " 43%|████▎     | 12/28 [00:03<00:05,  3.20it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.19it/s]\n",
      " 50%|█████     | 14/28 [00:04<00:04,  3.19it/s]\n",
      " 54%|█████▎    | 15/28 [00:04<00:04,  3.20it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.20it/s]\n",
      " 61%|██████    | 17/28 [00:05<00:03,  3.20it/s]\n",
      " 64%|██████▍   | 18/28 [00:05<00:03,  3.20it/s]\n",
      " 68%|██████▊   | 19/28 [00:05<00:02,  3.20it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.20it/s]\n",
      " 75%|███████▌  | 21/28 [00:06<00:02,  3.20it/s]\n",
      " 79%|███████▊  | 22/28 [00:06<00:01,  3.20it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.20it/s]\n",
      " 86%|████████▌ | 24/28 [00:07<00:01,  3.20it/s]\n",
      " 89%|████████▉ | 25/28 [00:07<00:00,  3.20it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.20it/s]\n",
      " 96%|█████████▋| 27/28 [00:08<00:00,  3.20it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.28it/s]\n",
      "02/20/2023 11:15:35 - INFO - __main__ - 0.7305045871559633\n",
      "02/20/2023 11:15:35 - INFO - __main__ - Checking the first example...\n",
      "02/20/2023 11:15:35 - INFO - __main__ - Input:\n",
      "02/20/2023 11:15:35 - INFO - __main__ - <|endoftext|>one long string of cliches. All in all\n",
      "02/20/2023 11:15:35 - INFO - __main__ - Output:\n",
      "02/20/2023 11:15:35 - INFO - __main__ -  terrible.<|endoftext|>\n",
      "02/20/2023 11:15:35 - INFO - __main__ - out\\gpt2-large\\direct\\SST-2\\test-t=2.pkl\n",
      "02/20/2023 11:15:35 - INFO - __main__ - Loading the model\n",
      "02/20/2023 11:15:44 - INFO - __main__ - Finished loading the model\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:10,  2.67it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:08,  2.95it/s]\n",
      " 11%|█         | 3/28 [00:01<00:08,  3.05it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:07,  3.10it/s]\n",
      " 18%|█▊        | 5/28 [00:01<00:07,  3.13it/s]\n",
      " 21%|██▏       | 6/28 [00:01<00:06,  3.15it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:06,  3.16it/s]\n",
      " 29%|██▊       | 8/28 [00:02<00:06,  3.17it/s]\n",
      " 32%|███▏      | 9/28 [00:02<00:05,  3.17it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.17it/s]\n",
      " 39%|███▉      | 11/28 [00:03<00:05,  3.17it/s]\n",
      " 43%|████▎     | 12/28 [00:03<00:05,  3.16it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.17it/s]\n",
      " 50%|█████     | 14/28 [00:04<00:04,  3.17it/s]\n",
      " 54%|█████▎    | 15/28 [00:04<00:04,  3.17it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.16it/s]\n",
      " 61%|██████    | 17/28 [00:05<00:03,  3.17it/s]\n",
      " 64%|██████▍   | 18/28 [00:05<00:03,  3.17it/s]\n",
      " 68%|██████▊   | 19/28 [00:06<00:02,  3.17it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.18it/s]\n",
      " 75%|███████▌  | 21/28 [00:06<00:02,  3.18it/s]\n",
      " 79%|███████▊  | 22/28 [00:06<00:01,  3.19it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.19it/s]\n",
      " 86%|████████▌ | 24/28 [00:07<00:01,  3.19it/s]\n",
      " 89%|████████▉ | 25/28 [00:07<00:00,  3.18it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.19it/s]\n",
      " 96%|█████████▋| 27/28 [00:08<00:00,  3.19it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.24it/s]\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:08,  3.20it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:08,  3.20it/s]\n",
      " 11%|█         | 3/28 [00:00<00:07,  3.20it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:07,  3.20it/s]\n",
      " 18%|█▊        | 5/28 [00:01<00:07,  3.19it/s]\n",
      " 21%|██▏       | 6/28 [00:01<00:06,  3.19it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:06,  3.19it/s]\n",
      " 29%|██▊       | 8/28 [00:02<00:06,  3.19it/s]\n",
      " 32%|███▏      | 9/28 [00:02<00:05,  3.19it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.18it/s]\n",
      " 39%|███▉      | 11/28 [00:03<00:05,  3.18it/s]\n",
      " 43%|████▎     | 12/28 [00:03<00:05,  3.19it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.19it/s]\n",
      " 50%|█████     | 14/28 [00:04<00:04,  3.18it/s]\n",
      " 54%|█████▎    | 15/28 [00:04<00:04,  3.19it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.19it/s]\n",
      " 61%|██████    | 17/28 [00:05<00:03,  3.18it/s]\n",
      " 64%|██████▍   | 18/28 [00:05<00:03,  3.18it/s]\n",
      " 68%|██████▊   | 19/28 [00:05<00:02,  3.19it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.19it/s]\n",
      " 75%|███████▌  | 21/28 [00:06<00:02,  3.18it/s]\n",
      " 79%|███████▊  | 22/28 [00:06<00:01,  3.18it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.19it/s]\n",
      " 86%|████████▌ | 24/28 [00:07<00:01,  3.19it/s]\n",
      " 89%|████████▉ | 25/28 [00:07<00:00,  3.19it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.18it/s]\n",
      " 96%|█████████▋| 27/28 [00:08<00:00,  3.18it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.27it/s]\n",
      "02/20/2023 11:16:01 - INFO - __main__ - 0.7385321100917431\n",
      "02/20/2023 11:16:01 - INFO - __main__ - Checking the first example...\n",
      "02/20/2023 11:16:01 - INFO - __main__ - Input:\n",
      "02/20/2023 11:16:01 - INFO - __main__ - <|endoftext|>one long string of cliches. A\n",
      "02/20/2023 11:16:01 - INFO - __main__ - Output:\n",
      "02/20/2023 11:16:01 - INFO - __main__ -  terrible piece.<|endoftext|>\n",
      "02/20/2023 11:16:01 - INFO - __main__ - out\\gpt2-large\\direct\\SST-2\\test-t=3.pkl\n",
      "02/20/2023 11:16:01 - INFO - __main__ - Loading the model\n",
      "02/20/2023 11:16:09 - INFO - __main__ - Finished loading the model\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:09,  2.70it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:08,  2.96it/s]\n",
      " 11%|█         | 3/28 [00:00<00:08,  3.06it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:07,  3.11it/s]\n",
      " 18%|█▊        | 5/28 [00:01<00:07,  3.13it/s]\n",
      " 21%|██▏       | 6/28 [00:01<00:06,  3.15it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:06,  3.15it/s]\n",
      " 29%|██▊       | 8/28 [00:02<00:06,  3.17it/s]\n",
      " 32%|███▏      | 9/28 [00:02<00:05,  3.17it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.17it/s]\n",
      " 39%|███▉      | 11/28 [00:03<00:05,  3.17it/s]\n",
      " 43%|████▎     | 12/28 [00:03<00:05,  3.18it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.18it/s]\n",
      " 50%|█████     | 14/28 [00:04<00:04,  3.18it/s]\n",
      " 54%|█████▎    | 15/28 [00:04<00:04,  3.18it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.18it/s]\n",
      " 61%|██████    | 17/28 [00:05<00:03,  3.18it/s]\n",
      " 64%|██████▍   | 18/28 [00:05<00:03,  3.18it/s]\n",
      " 68%|██████▊   | 19/28 [00:06<00:02,  3.18it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.18it/s]\n",
      " 75%|███████▌  | 21/28 [00:06<00:02,  3.19it/s]\n",
      " 79%|███████▊  | 22/28 [00:06<00:01,  3.19it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.19it/s]\n",
      " 86%|████████▌ | 24/28 [00:07<00:01,  3.18it/s]\n",
      " 89%|████████▉ | 25/28 [00:07<00:00,  3.18it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.18it/s]\n",
      " 96%|█████████▋| 27/28 [00:08<00:00,  3.18it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.24it/s]\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "  4%|▎         | 1/28 [00:00<00:08,  3.18it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:08,  3.18it/s]\n",
      " 11%|█         | 3/28 [00:00<00:07,  3.18it/s]\n",
      " 14%|█▍        | 4/28 [00:01<00:07,  3.18it/s]\n",
      " 18%|█▊        | 5/28 [00:01<00:07,  3.18it/s]\n",
      " 21%|██▏       | 6/28 [00:01<00:06,  3.18it/s]\n",
      " 25%|██▌       | 7/28 [00:02<00:06,  3.18it/s]\n",
      " 29%|██▊       | 8/28 [00:02<00:06,  3.18it/s]\n",
      " 32%|███▏      | 9/28 [00:02<00:05,  3.18it/s]\n",
      " 36%|███▌      | 10/28 [00:03<00:05,  3.18it/s]\n",
      " 39%|███▉      | 11/28 [00:03<00:05,  3.18it/s]\n",
      " 43%|████▎     | 12/28 [00:03<00:05,  3.18it/s]\n",
      " 46%|████▋     | 13/28 [00:04<00:04,  3.18it/s]\n",
      " 50%|█████     | 14/28 [00:04<00:04,  3.18it/s]\n",
      " 54%|█████▎    | 15/28 [00:04<00:04,  3.18it/s]\n",
      " 57%|█████▋    | 16/28 [00:05<00:03,  3.18it/s]\n",
      " 61%|██████    | 17/28 [00:05<00:03,  3.17it/s]\n",
      " 64%|██████▍   | 18/28 [00:05<00:03,  3.17it/s]\n",
      " 68%|██████▊   | 19/28 [00:05<00:02,  3.18it/s]\n",
      " 71%|███████▏  | 20/28 [00:06<00:02,  3.18it/s]\n",
      " 75%|███████▌  | 21/28 [00:06<00:02,  3.18it/s]\n",
      " 79%|███████▊  | 22/28 [00:06<00:01,  3.18it/s]\n",
      " 82%|████████▏ | 23/28 [00:07<00:01,  3.18it/s]\n",
      " 86%|████████▌ | 24/28 [00:07<00:01,  3.18it/s]\n",
      " 89%|████████▉ | 25/28 [00:07<00:00,  3.18it/s]\n",
      " 93%|█████████▎| 26/28 [00:08<00:00,  3.18it/s]\n",
      " 96%|█████████▋| 27/28 [00:08<00:00,  3.18it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.26it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\fourlab\\Channel-LM-Prompting\\main.py\", line 413, in <module>\n",
      "    main(logger, args)\n",
      "  File \"c:\\Users\\fourlab\\Channel-LM-Prompting\\main.py\", line 77, in main\n",
      "    acc = run(logger, args.do_train, args.do_zeroshot,\n",
      "  File \"c:\\Users\\fourlab\\Channel-LM-Prompting\\main.py\", line 330, in run\n",
      "    with open(cache_path, \"wb\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'out\\\\gpt2-large\\\\direct\\\\SST-2\\\\test-t=3.pkl'\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --task \"SST-2\" \\\n",
    "    --split test \\\n",
    "    --data_dir data \\\n",
    "    --out_dir out \\\n",
    "    --gpt2 gpt2-large \\\n",
    "    --do_zeroshot \\\n",
    "    --method direct "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p391",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f538ca4f02e717986d92efcc8525643b76f5ec3fa5431803427aee56bb77e7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
